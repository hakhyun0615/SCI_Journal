{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43232b7",
   "metadata": {},
   "source": [
    "# Embedding 학습 및 테스트 (Embedding Training and Testing)\n",
    "\n",
    "**학습 데이터**: `MissingValue/gp_2021.xlsx`  \n",
    "**테스트 데이터**: `MissingValue/table_merge_2023.xlsx`\n",
    "\n",
    "이 노트북에서는 아파트 거래 데이터를 사용하여 범주형 변수에 대한 임베딩을 학습하고, 학습된 임베딩을 사용하여 아파트 가격을 예측하는 모델을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f120e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"라이브러리 임포트 완료\")\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534c60a",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 탐색적 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988fc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "print(\"=== 데이터 로드 ===\")\n",
    "train_data_path = '../../데이터/MissingValue/gp_2021.xlsx'\n",
    "test_data_path = '../../데이터/MissingValue/table_merge_2023.xlsx'\n",
    "\n",
    "try:\n",
    "    train_data = pd.read_excel(train_data_path)\n",
    "    print(f\"✓ 학습 데이터 로드 완료: {train_data.shape}\")\n",
    "    print(f\"  컬럼 수: {len(train_data.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ 학습 데이터 로드 실패: {e}\")\n",
    "    train_data = None\n",
    "\n",
    "try:\n",
    "    test_data = pd.read_excel(test_data_path)\n",
    "    print(f\"✓ 테스트 데이터 로드 완료: {test_data.shape}\")\n",
    "    print(f\"  컬럼 수: {len(test_data.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ 테스트 데이터 로드 실패: {e}\")\n",
    "    test_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 기본 정보 확인\n",
    "if train_data is not None:\n",
    "    print(\"=== 학습 데이터 정보 ===\")\n",
    "    print(train_data.info())\n",
    "    print(\"\\n=== 학습 데이터 샘플 ===\")\n",
    "    display(train_data.head())\n",
    "    \n",
    "    print(\"\\n=== 학습 데이터 기술통계 ===\")\n",
    "    display(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data is not None:\n",
    "    print(\"=== 테스트 데이터 정보 ===\")\n",
    "    print(test_data.info())\n",
    "    print(\"\\n=== 테스트 데이터 샘플 ===\")\n",
    "    display(test_data.head())\n",
    "    \n",
    "    print(\"\\n=== 테스트 데이터 기술통계 ===\")\n",
    "    display(test_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 확인\n",
    "if train_data is not None and test_data is not None:\n",
    "    print(\"=== 결측값 분석 ===\")\n",
    "    \n",
    "    # 공통 컬럼 확인\n",
    "    common_cols = set(train_data.columns) & set(test_data.columns)\n",
    "    train_only = set(train_data.columns) - set(test_data.columns)\n",
    "    test_only = set(test_data.columns) - set(train_data.columns)\n",
    "    \n",
    "    print(f\"공통 컬럼: {len(common_cols)}개\")\n",
    "    print(f\"학습 데이터만: {len(train_only)}개 - {list(train_only)[:5]}...\")\n",
    "    print(f\"테스트 데이터만: {len(test_only)}개 - {list(test_only)[:5]}...\")\n",
    "    \n",
    "    # 결측값 시각화\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 학습 데이터 결측값\n",
    "    train_missing = train_data.isnull().sum().sort_values(ascending=False)\n",
    "    train_missing_pct = (train_missing / len(train_data) * 100).head(20)\n",
    "    \n",
    "    axes[0].barh(range(len(train_missing_pct)), train_missing_pct.values)\n",
    "    axes[0].set_yticks(range(len(train_missing_pct)))\n",
    "    axes[0].set_yticklabels(train_missing_pct.index, fontsize=8)\n",
    "    axes[0].set_xlabel('Missing Percentage (%)')\n",
    "    axes[0].set_title('Training Data - Missing Values')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 테스트 데이터 결측값\n",
    "    test_missing = test_data.isnull().sum().sort_values(ascending=False)\n",
    "    test_missing_pct = (test_missing / len(test_data) * 100).head(20)\n",
    "    \n",
    "    axes[1].barh(range(len(test_missing_pct)), test_missing_pct.values)\n",
    "    axes[1].set_yticks(range(len(test_missing_pct)))\n",
    "    axes[1].set_yticklabels(test_missing_pct.index, fontsize=8)\n",
    "    axes[1].set_xlabel('Missing Percentage (%)')\n",
    "    axes[1].set_title('Test Data - Missing Values')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf262e",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 및 변수 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170acba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    \"\"\"\n",
    "    학습 및 테스트 데이터 전처리\n",
    "    \"\"\"\n",
    "    print(\"=== 데이터 전처리 ===\")\n",
    "    \n",
    "    # 공통 컬럼 확인\n",
    "    common_cols = set(train_data.columns) & set(test_data.columns)\n",
    "    print(f\"공통 컬럼 수: {len(common_cols)}\")\n",
    "    \n",
    "    # 타겟 변수 확인 (가격 관련 컬럼 찾기)\n",
    "    price_cols = [col for col in train_data.columns if 'price' in col.lower() or '가격' in col.lower()]\n",
    "    if price_cols:\n",
    "        target_col = price_cols[0]\n",
    "        print(f\"타겟 변수: {target_col}\")\n",
    "    else:\n",
    "        # 기본적으로 마지막 수치형 컬럼을 타겟으로 사용\n",
    "        numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        target_col = numeric_cols[-1] if numeric_cols else None\n",
    "        print(f\"기본 타겟 변수: {target_col}\")\n",
    "    \n",
    "    # 범주형/수치형 변수 분리\n",
    "    categorical_cols = []\n",
    "    numerical_cols = []\n",
    "    \n",
    "    for col in common_cols:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "            \n",
    "        if train_data[col].dtype == 'object' or train_data[col].nunique() < 50:\n",
    "            categorical_cols.append(col)\n",
    "        else:\n",
    "            numerical_cols.append(col)\n",
    "    \n",
    "    print(f\"범주형 변수 ({len(categorical_cols)}개): {categorical_cols[:10]}...\")\n",
    "    print(f\"수치형 변수 ({len(numerical_cols)}개): {numerical_cols[:10]}...\")\n",
    "    \n",
    "    return categorical_cols, numerical_cols, target_col\n",
    "\n",
    "if train_data is not None and test_data is not None:\n",
    "    categorical_cols, numerical_cols, target_col = preprocess_data(train_data, test_data)\n",
    "else:\n",
    "    print(\"데이터 로드 실패로 전처리를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수별 분포 시각화\n",
    "if train_data is not None and target_col is not None:\n",
    "    print(\"=== 타겟 변수 분포 분석 ===\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 히스토그램\n",
    "    axes[0, 0].hist(train_data[target_col].dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_title(f'{target_col} Distribution')\n",
    "    axes[0, 0].set_xlabel(target_col)\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 박스플롯\n",
    "    axes[0, 1].boxplot(train_data[target_col].dropna())\n",
    "    axes[0, 1].set_title(f'{target_col} Box Plot')\n",
    "    axes[0, 1].set_ylabel(target_col)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 로그 변환 히스토그램\n",
    "    log_target = np.log(train_data[target_col].dropna() + 1)\n",
    "    axes[1, 0].hist(log_target, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[1, 0].set_title(f'Log({target_col}) Distribution')\n",
    "    axes[1, 0].set_xlabel(f'Log({target_col})')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q-Q 플롯\n",
    "    from scipy import stats\n",
    "    stats.probplot(train_data[target_col].dropna(), dist=\"norm\", plot=axes[1, 1])\n",
    "    axes[1, 1].set_title(f'{target_col} Q-Q Plot')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 타겟 변수 기술통계\n",
    "    print(f\"\\n{target_col} 기술통계:\")\n",
    "    print(train_data[target_col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751ddb4",
   "metadata": {},
   "source": [
    "## 3. Embedding 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApartmentEmbeddingModel(nn.Module):\n",
    "    def __init__(self, categorical_dims, embedding_dims, numerical_features, hidden_dim=512, output_dim=1):\n",
    "        \"\"\"\n",
    "        아파트 데이터용 Embedding 모델\n",
    "        \n",
    "        Args:\n",
    "            categorical_dims: 각 범주형 변수의 고유값 개수 딕셔너리\n",
    "            embedding_dims: 각 범주형 변수의 임베딩 차원 딕셔너리\n",
    "            numerical_features: 수치형 변수 개수\n",
    "            hidden_dim: 은닉층 차원\n",
    "            output_dim: 출력 차원 (가격 예측이므로 1)\n",
    "        \"\"\"\n",
    "        super(ApartmentEmbeddingModel, self).__init__()\n",
    "        \n",
    "        # Embedding 레이어 생성\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        total_embedding_dim = 0\n",
    "        \n",
    "        for col_name, num_categories in categorical_dims.items():\n",
    "            embed_dim = embedding_dims[col_name]\n",
    "            self.embeddings[col_name] = nn.Embedding(num_categories, embed_dim)\n",
    "            total_embedding_dim += embed_dim\n",
    "        \n",
    "        # 전체 입력 차원 = 임베딩 차원 + 수치형 변수 차원\n",
    "        total_input_dim = total_embedding_dim + numerical_features\n",
    "        \n",
    "        # 신경망 레이어\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(total_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim // 4, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, categorical_inputs, numerical_inputs):\n",
    "        # 각 범주형 변수에 대한 임베딩 계산\n",
    "        embedded_features = []\n",
    "        for col_name, cat_input in categorical_inputs.items():\n",
    "            embedded = self.embeddings[col_name](cat_input)\n",
    "            embedded_features.append(embedded)\n",
    "        \n",
    "        # 모든 임베딩을 연결\n",
    "        if embedded_features:\n",
    "            embedded_concat = torch.cat(embedded_features, dim=1)\n",
    "            # 수치형 변수와 결합\n",
    "            combined_features = torch.cat([embedded_concat, numerical_inputs], dim=1)\n",
    "        else:\n",
    "            combined_features = numerical_inputs\n",
    "        \n",
    "        # 신경망을 통한 예측\n",
    "        output = self.fc_layers(combined_features)\n",
    "        return output\n",
    "\n",
    "print(\"Embedding 모델 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80502870",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab32be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApartmentDataset(Dataset):\n",
    "    def __init__(self, data, categorical_cols, numerical_cols, target_col, \n",
    "                 categorical_encoders=None, numerical_scaler=None, is_train=True):\n",
    "        \"\"\"\n",
    "        아파트 데이터셋 클래스\n",
    "        \"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.target_col = target_col\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        if categorical_encoders is None:\n",
    "            self.categorical_encoders = {}\n",
    "            for col in categorical_cols:\n",
    "                if col in self.data.columns:\n",
    "                    le = LabelEncoder()\n",
    "                    self.data[col] = le.fit_transform(self.data[col].astype(str))\n",
    "                    self.categorical_encoders[col] = le\n",
    "        else:\n",
    "            self.categorical_encoders = categorical_encoders\n",
    "            for col in categorical_cols:\n",
    "                if col in self.data.columns:\n",
    "                    le = self.categorical_encoders[col]\n",
    "                    try:\n",
    "                        self.data[col] = le.transform(self.data[col].astype(str))\n",
    "                    except ValueError:\n",
    "                        # 새로운 범주 처리\n",
    "                        self.data[col] = 0  # 또는 다른 기본값\n",
    "        \n",
    "        # 수치형 변수 정규화\n",
    "        if numerical_scaler is None and is_train:\n",
    "            self.numerical_scaler = StandardScaler()\n",
    "            if numerical_cols:\n",
    "                self.data[numerical_cols] = self.numerical_scaler.fit_transform(\n",
    "                    self.data[numerical_cols].fillna(0)\n",
    "                )\n",
    "        elif numerical_scaler is not None:\n",
    "            self.numerical_scaler = numerical_scaler\n",
    "            if numerical_cols:\n",
    "                self.data[numerical_cols] = self.numerical_scaler.transform(\n",
    "                    self.data[numerical_cols].fillna(0)\n",
    "                )\n",
    "        else:\n",
    "            self.numerical_scaler = None\n",
    "            \n",
    "        # 타겟 변수 처리\n",
    "        if target_col in self.data.columns:\n",
    "            self.targets = self.data[target_col].values.astype(np.float32)\n",
    "        else:\n",
    "            self.targets = np.zeros(len(self.data))  # 테스트 데이터의 경우\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 범주형 변수\n",
    "        categorical_data = {}\n",
    "        for col in self.categorical_cols:\n",
    "            if col in self.data.columns:\n",
    "                categorical_data[col] = torch.tensor(self.data.iloc[idx][col], dtype=torch.long)\n",
    "        \n",
    "        # 수치형 변수\n",
    "        numerical_data = []\n",
    "        for col in self.numerical_cols:\n",
    "            if col in self.data.columns:\n",
    "                numerical_data.append(self.data.iloc[idx][col])\n",
    "        \n",
    "        numerical_tensor = torch.tensor(numerical_data, dtype=torch.float32) if numerical_data else torch.tensor([], dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        \n",
    "        return categorical_data, numerical_tensor, target\n",
    "\n",
    "print(\"데이터셋 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb4d26",
   "metadata": {},
   "source": [
    "## 5. 모델 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_data is not None and test_data is not None:\n",
    "    # 학습/검증 데이터 분할\n",
    "    train_df, val_df = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "    print(f\"학습 데이터: {len(train_df):,}개\")\n",
    "    print(f\"검증 데이터: {len(val_df):,}개\")\n",
    "    print(f\"테스트 데이터: {len(test_data):,}개\")\n",
    "    \n",
    "    # 데이터셋 생성\n",
    "    train_dataset = ApartmentDataset(\n",
    "        train_df, categorical_cols, numerical_cols, target_col, \n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ApartmentDataset(\n",
    "        val_df, categorical_cols, numerical_cols, target_col,\n",
    "        categorical_encoders=train_dataset.categorical_encoders,\n",
    "        numerical_scaler=train_dataset.numerical_scaler,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    test_dataset = ApartmentDataset(\n",
    "        test_data, categorical_cols, numerical_cols, target_col,\n",
    "        categorical_encoders=train_dataset.categorical_encoders,\n",
    "        numerical_scaler=train_dataset.numerical_scaler,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # 데이터 로더 생성\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"데이터 로더 생성 완료 (배치 크기: {batch_size})\")\n",
    "    \n",
    "    # 임베딩 차원 설정\n",
    "    categorical_dims = {}\n",
    "    embedding_dims = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in train_data.columns:\n",
    "            unique_count = len(train_dataset.categorical_encoders[col].classes_)\n",
    "            categorical_dims[col] = unique_count\n",
    "            # 임베딩 차원은 일반적으로 고유값 개수의 절반 정도로 설정 (최소 4, 최대 50)\n",
    "            embedding_dims[col] = min(50, max(4, unique_count // 2))\n",
    "    \n",
    "    print(f\"\\n범주형 변수 임베딩 설정:\")\n",
    "    for col in categorical_dims:\n",
    "        print(f\"  {col}: {categorical_dims[col]} → {embedding_dims[col]}차원\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b63e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "if train_data is not None and test_data is not None:\n",
    "    model = ApartmentEmbeddingModel(\n",
    "        categorical_dims=categorical_dims,\n",
    "        embedding_dims=embedding_dims,\n",
    "        numerical_features=len(numerical_cols),\n",
    "        hidden_dim=512,\n",
    "        output_dim=1\n",
    "    )\n",
    "    \n",
    "    print(f\"모델 생성 완료\")\n",
    "    print(f\"모델 파라미터 수: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # 모델 구조 출력\n",
    "    print(\"\\n모델 구조:\")\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486573a",
   "metadata": {},
   "source": [
    "## 6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32630a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=50, lr=0.001):\n",
    "    \"\"\"\n",
    "    모델 학습\n",
    "    \"\"\"\n",
    "    print(f\"=== 모델 학습 시작 ===\")\n",
    "    print(f\"Epochs: {epochs}, Learning Rate: {lr}\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 학습 모드\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_count = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for categorical_data, numerical_data, targets in progress_bar:\n",
    "            # 데이터를 GPU로 이동\n",
    "            categorical_inputs = {k: v.to(device) for k, v in categorical_data.items()}\n",
    "            numerical_inputs = numerical_data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(categorical_inputs, numerical_inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            \n",
    "            # 역전파\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_count += 1\n",
    "            \n",
    "            # 진행률 표시 업데이트\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_train_loss = train_loss / train_count\n",
    "        \n",
    "        # 검증 모드\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for categorical_data, numerical_data, targets in val_loader:\n",
    "                categorical_inputs = {k: v.to(device) for k, v in categorical_data.items()}\n",
    "                numerical_inputs = numerical_data.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model(categorical_inputs, numerical_inputs)\n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_count += 1\n",
    "        \n",
    "        avg_val_loss = val_loss / val_count if val_count > 0 else float('inf')\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # 최고 모델 저장\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # 최고 모델 로드\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    print(f\"\\n학습 완료! 최고 검증 손실: {best_val_loss:.4f}\")\n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 실행\n",
    "if train_data is not None and test_data is not None:\n",
    "    trained_model, train_losses, val_losses = train_model(\n",
    "        model, train_loader, val_loader, epochs=50, lr=0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e507fdc",
   "metadata": {},
   "source": [
    "## 7. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, test_targets=None):\n",
    "    \"\"\"\n",
    "    모델 평가\n",
    "    \"\"\"\n",
    "    print(\"=== 모델 평가 ===\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for categorical_data, numerical_data, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            categorical_inputs = {k: v.to(device) for k, v in categorical_data.items()}\n",
    "            numerical_inputs = numerical_data.to(device)\n",
    "            \n",
    "            outputs = model(categorical_inputs, numerical_inputs)\n",
    "            predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "            \n",
    "            if test_targets is not None:\n",
    "                actuals.extend(targets.numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    if test_targets is not None:\n",
    "        actuals = np.array(actuals)\n",
    "        \n",
    "        # 평가 메트릭 계산\n",
    "        mse = np.mean((predictions - actuals) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(predictions - actuals))\n",
    "        \n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        \n",
    "        # 상관관계\n",
    "        correlation = np.corrcoef(predictions, actuals)[0, 1]\n",
    "        print(f\"Correlation: {correlation:.4f}\")\n",
    "        \n",
    "        return predictions, actuals, {'mse': mse, 'rmse': rmse, 'mae': mae, 'correlation': correlation}\n",
    "    else:\n",
    "        return predictions, None, None\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "if train_data is not None and test_data is not None:\n",
    "    test_targets = test_data[target_col].values if target_col in test_data.columns else None\n",
    "    predictions, actuals, metrics = evaluate_model(trained_model, test_loader, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67444c9a",
   "metadata": {},
   "source": [
    "## 8. 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 및 예측 결과 시각화\n",
    "if train_data is not None and test_data is not None:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 학습 곡선\n",
    "    axes[0, 0].plot(train_losses, label='Train Loss', color='blue', linewidth=2)\n",
    "    axes[0, 0].plot(val_losses, label='Validation Loss', color='red', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    if predictions is not None and actuals is not None:\n",
    "        # 예측 vs 실제\n",
    "        axes[0, 1].scatter(actuals, predictions, alpha=0.6, color='purple', s=20)\n",
    "        axes[0, 1].plot([actuals.min(), actuals.max()], [actuals.min(), actuals.max()], 'r--', lw=2)\n",
    "        axes[0, 1].set_xlabel('Actual Values')\n",
    "        axes[0, 1].set_ylabel('Predicted Values')\n",
    "        axes[0, 1].set_title('Predicted vs Actual')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 잔차 플롯\n",
    "        residuals = predictions - actuals\n",
    "        axes[0, 2].scatter(predictions, residuals, alpha=0.6, color='green', s=20)\n",
    "        axes[0, 2].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "        axes[0, 2].set_xlabel('Predicted Values')\n",
    "        axes[0, 2].set_ylabel('Residuals')\n",
    "        axes[0, 2].set_title('Residual Plot')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 예측값 분포\n",
    "        axes[1, 0].hist(predictions, bins=30, alpha=0.7, color='skyblue', edgecolor='black', label='Predictions')\n",
    "        axes[1, 0].hist(actuals, bins=30, alpha=0.7, color='orange', edgecolor='black', label='Actuals')\n",
    "        axes[1, 0].set_xlabel('Values')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].set_title('Distribution of Predictions vs Actuals')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 잔차 히스토그램\n",
    "        axes[1, 1].hist(residuals, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "        axes[1, 1].set_xlabel('Residuals')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('Residuals Distribution')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 에러 메트릭 시각화\n",
    "        if metrics:\n",
    "            metric_names = ['MSE', 'RMSE', 'MAE']\n",
    "            metric_values = [metrics['mse'], metrics['rmse'], metrics['mae']]\n",
    "            \n",
    "            bars = axes[1, 2].bar(metric_names, metric_values, color=['red', 'orange', 'green'], alpha=0.7)\n",
    "            axes[1, 2].set_ylabel('Value')\n",
    "            axes[1, 2].set_title('Evaluation Metrics')\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "            \n",
    "            # 막대 위에 값 표시\n",
    "            for bar, value in zip(bars, metric_values):\n",
    "                height = bar.get_height()\n",
    "                axes[1, 2].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                               f'{value:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../../데이터/Figure/original/Embedding_Training_Results.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66649a",
   "metadata": {},
   "source": [
    "## 9. 임베딩 벡터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a57d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 벡터 추출 및 분석\n",
    "if train_data is not None and test_data is not None:\n",
    "    print(\"=== 임베딩 벡터 분석 ===\")\n",
    "    \n",
    "    trained_model.eval()\n",
    "    embeddings_analysis = {}\n",
    "    \n",
    "    for col_name, embedding_layer in trained_model.embeddings.items():\n",
    "        if col_name in categorical_dims:\n",
    "            # 해당 범주형 변수의 모든 임베딩 벡터 추출\n",
    "            num_categories = categorical_dims[col_name]\n",
    "            embedding_vectors = embedding_layer.weight.data.cpu().numpy()\n",
    "            \n",
    "            print(f\"\\n{col_name} 임베딩:\")\n",
    "            print(f\"  - 범주 수: {num_categories}\")\n",
    "            print(f\"  - 임베딩 차원: {embedding_vectors.shape[1]}\")\n",
    "            print(f\"  - 임베딩 벡터 형태: {embedding_vectors.shape}\")\n",
    "            \n",
    "            # 임베딩 벡터의 유사도 분석 (상위 5개 범주만)\n",
    "            if num_categories <= 20:  # 범주가 너무 많지 않은 경우만\n",
    "                similarity_matrix = cosine_similarity(embedding_vectors)\n",
    "                \n",
    "                print(f\"  - 임베딩 유사도 (상위 5x5):\")\n",
    "                print(f\"    {similarity_matrix[:5, :5]}\")\n",
    "            \n",
    "            embeddings_analysis[col_name] = embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06069c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 시각화 (차원 축소)\n",
    "if train_data is not None and test_data is not None and len(embeddings_analysis) > 0:\n",
    "    print(\"=== 임베딩 시각화 ===\")\n",
    "    \n",
    "    # 시각화할 임베딩 선택 (상위 3개)\n",
    "    embeddings_to_plot = list(embeddings_analysis.items())[:3]\n",
    "    \n",
    "    if len(embeddings_to_plot) > 0:\n",
    "        fig, axes = plt.subplots(2, len(embeddings_to_plot), figsize=(5*len(embeddings_to_plot), 10))\n",
    "        if len(embeddings_to_plot) == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "        \n",
    "        for idx, (col_name, embeddings) in enumerate(embeddings_to_plot):\n",
    "            if embeddings.shape[0] <= 100:  # 너무 많은 범주는 제외\n",
    "                # PCA\n",
    "                if embeddings.shape[1] >= 2:\n",
    "                    pca = PCA(n_components=2)\n",
    "                    pca_result = pca.fit_transform(embeddings)\n",
    "                    \n",
    "                    axes[0, idx].scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7, s=50)\n",
    "                    axes[0, idx].set_title(f'{col_name} - PCA')\n",
    "                    axes[0, idx].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "                    axes[0, idx].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "                    axes[0, idx].grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # 일부 포인트에 라벨 추가 (처음 10개)\n",
    "                    for i in range(min(10, len(pca_result))):\n",
    "                        axes[0, idx].annotate(f'{i}', (pca_result[i, 0], pca_result[i, 1]), \n",
    "                                            xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "                    \n",
    "                    # t-SNE (데이터가 너무 많지 않은 경우)\n",
    "                    if embeddings.shape[0] <= 50 and embeddings.shape[0] > 5:\n",
    "                        perplexity = min(30, embeddings.shape[0]-1)\n",
    "                        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
    "                        tsne_result = tsne.fit_transform(embeddings)\n",
    "                        \n",
    "                        axes[1, idx].scatter(tsne_result[:, 0], tsne_result[:, 1], alpha=0.7, s=50)\n",
    "                        axes[1, idx].set_title(f'{col_name} - t-SNE')\n",
    "                        axes[1, idx].set_xlabel('t-SNE 1')\n",
    "                        axes[1, idx].set_ylabel('t-SNE 2')\n",
    "                        axes[1, idx].grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # 일부 포인트에 라벨 추가\n",
    "                        for i in range(min(10, len(tsne_result))):\n",
    "                            axes[1, idx].annotate(f'{i}', (tsne_result[i, 0], tsne_result[i, 1]), \n",
    "                                                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "                    else:\n",
    "                        axes[1, idx].text(0.5, 0.5, 'Too few/many\\ndata points\\nfor t-SNE', \n",
    "                                         ha='center', va='center', transform=axes[1, idx].transAxes)\n",
    "                        axes[1, idx].set_title(f'{col_name} - t-SNE (N/A)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../../데이터/Figure/original/Embedding_Visualization.jpg', dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b00b1",
   "metadata": {},
   "source": [
    "## 10. 모델 저장 및 최종 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "if train_data is not None and test_data is not None:\n",
    "    model_save_path = '../../데이터/Checkpoint/embedding/apartment_embedding_model.pth'\n",
    "    \n",
    "    # 디렉토리 생성\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': trained_model.state_dict(),\n",
    "        'categorical_dims': categorical_dims,\n",
    "        'embedding_dims': embedding_dims,\n",
    "        'categorical_encoders': train_dataset.categorical_encoders,\n",
    "        'numerical_scaler': train_dataset.numerical_scaler,\n",
    "        'categorical_cols': categorical_cols,\n",
    "        'numerical_cols': numerical_cols,\n",
    "        'target_col': target_col,\n",
    "        'metrics': metrics\n",
    "    }, model_save_path)\n",
    "    \n",
    "    print(f\"모델이 저장되었습니다: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 요약\n",
    "if train_data is not None and test_data is not None:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"임베딩 학습 및 테스트 완료 (Embedding Training and Testing Completed)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if metrics:\n",
    "        print(f\"\\n최종 성능 지표:\")\n",
    "        print(f\"  - RMSE: {metrics['rmse']:.4f}\")\n",
    "        print(f\"  - MAE: {metrics['mae']:.4f}\")\n",
    "        print(f\"  - 상관계수: {metrics['correlation']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n생성된 파일:\")\n",
    "    print(f\"  - 모델 체크포인트: {model_save_path}\")\n",
    "    print(f\"  - 학습 결과 그래프: ../../데이터/Figure/original/Embedding_Training_Results.jpg\")\n",
    "    print(f\"  - 임베딩 시각화: ../../데이터/Figure/original/Embedding_Visualization.jpg\")\n",
    "    \n",
    "    print(f\"\\n임베딩 요약:\")\n",
    "    total_embedding_params = sum(\n",
    "        categorical_dims[col] * embedding_dims[col] \n",
    "        for col in categorical_dims\n",
    "    )\n",
    "    print(f\"  - 총 임베딩 파라미터: {total_embedding_params:,}\")\n",
    "    print(f\"  - 범주형 변수 수: {len(categorical_cols)}\")\n",
    "    print(f\"  - 수치형 변수 수: {len(numerical_cols)}\")\n",
    "    \n",
    "    # 데이터 정보 요약\n",
    "    print(f\"\\n데이터 정보:\")\n",
    "    print(f\"  - 학습 데이터: {len(train_df):,}개\")\n",
    "    print(f\"  - 검증 데이터: {len(val_df):,}개\")\n",
    "    print(f\"  - 테스트 데이터: {len(test_data):,}개\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n데이터 로드 실패로 인해 임베딩 학습을 진행할 수 없었습니다.\")\n",
    "    print(\"파일 경로와 데이터 형식을 확인해주세요.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"노트북 실행 완료\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
