{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from Dataset.Embedding_Dataset import Embedding_Dataset\n",
    "from Model.Embedding import Embedding\n",
    "\n",
    "from Dataset.Apartment_Complex_Dataset import Apartment_Complex_Dataset\n",
    "from Model.LSTM import LSTM\n",
    "from Model.GRU import GRU\n",
    "from Model.Transformer import Transformer\n",
    "from Model.Informer import Informer\n",
    "from Model.Pyraformer import Pyraformer\n",
    "from Model.N_BEATS import NBeats\n",
    "from Model.NLinear import NLinear\n",
    "\n",
    "from Dataset.District_Dataset import District_Dataset \n",
    "from Model.LSTM_Attention import LSTMAttention\n",
    "from Model.GRU_Attention import GRUAttention\n",
    "from Model.Transformer_Attention import TransformerAttention\n",
    "from Model.Informer_Attention import InformerAttention\n",
    "\n",
    "from utils import RMSE, rmse, mse, mae, save_train_val_losses\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# connection_info = \"host=localhost dbname=postgres user=postgres password=hd219833 port=5432\"\n",
    "# conn = psycopg2.connect(connection_info)\n",
    "# table_1_query = '''\n",
    "#     SELECT * FROM building\n",
    "#     '''\n",
    "# table_2_query = '''\n",
    "#     SELECT * FROM economy\n",
    "#     '''\n",
    "# table_3_query = '''\n",
    "#     SELECT * FROM building_price\n",
    "#     '''\n",
    "# table_1 = pd.read_sql(table_1_query,conn) \n",
    "# table_2 = pd.read_sql(table_2_query,conn)\n",
    "# table_3 = pd.read_sql(table_3_query,conn) \n",
    "\n",
    "table_1 = pd.read_csv('../데이터/Table/table_1.csv') \n",
    "table_2 = pd.read_csv('../데이터/Table/table_2.csv') \n",
    "table_3 = pd.read_csv('../데이터/Table/table_3.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "lr = 1e-4\n",
    "batch = 64\n",
    "hidden_dim = 1024\n",
    "sub = True\n",
    "embedding_dim = 1024\n",
    "window_size = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = torch.load(\"../데이터/Checkpoint/embedding/default/embedding_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_13.pth\", map_location=DEVICE)\n",
    "dataset = District_Dataset(embedding_model, table_1, table_2, table_3, embedding_dim, window_size, sub, DEVICE)\n",
    "dataset_length = len(dataset)\n",
    "train_size = int(train_ratio * dataset_length)\n",
    "# train_indices = range(0, train_size)\n",
    "val_size = int(val_ratio * dataset_length)\n",
    "# val_indices = range(train_size, train_size + val_size)\n",
    "test_size = int(test_ratio * dataset_length)\n",
    "test_indices = range(train_size + val_size, dataset_length)\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "# val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=False, drop_last=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=batch, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "# model = torch.load(\"../데이터/Checkpoint/lstm/default/lstm_lr_0.0001_batch_64_hid_1024_sub_True_emb_1024_ws_12_epochs_10.pth\", map_location=DEVICE)\n",
    "\n",
    "# GRU\n",
    "# model = torch.load(\"../데이터/Checkpoint/gru/default/gru_lr_0.0001_batch_64_hid_1024_sub_True_emb_1024_ws_12_epochs_9.pth\", map_location=DEVICE)\n",
    "\n",
    "# transformer\n",
    "# model = torch.load(\"../데이터/Checkpoint/transformer/default/transformer_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_15.pth\", map_location=DEVICE)\n",
    "\n",
    "# Informer\n",
    "# model = torch.load(f'../데이터/Checkpoint/informer/informer_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_28.pth', map_location=DEVICE)\n",
    "\n",
    "# Pyraformer\n",
    "# model = torch.load(f'../데이터/Checkpoint/pyraformer/pyraformer_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_5.pth', map_location=DEVICE)\n",
    "\n",
    "# N_BEATS\n",
    "# model = torch.load(f'../데이터/Checkpoint/n_beats/n_beats_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_7.pth', map_location=DEVICE)\n",
    "\n",
    "# NLinear\n",
    "# model = torch.load(f'../데이터/Checkpoint/nlinear/nlinear_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_25.pth', map_location=DEVICE)\n",
    "\n",
    "# LSTM attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/lstm/attention/lstm_attention_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_8.pth\", map_location=DEVICE)\n",
    "\n",
    "# GRU attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/gru/attention/gru_attention_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_4.pth\", map_location=DEVICE)\n",
    "\n",
    "# Transformer attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/transformer/attention/default/transformer_attention_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_5.pth\", map_location=DEVICE)\n",
    "\n",
    "# Informer attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/informer_attention/informer_attention_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_5.pth\", map_location=DEVICE)\n",
    "\n",
    "# Pyraformer attention\n",
    "model = torch.load(\"../데이터/Checkpoint/pyraformer_attention/pyraformer_attention_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_8.pth\", map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 2.7784\n",
      "Test MSE: 7.7197\n",
      "Test MAE: 1.9717\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_rmses = []\n",
    "test_mses = []\n",
    "test_maes = []\n",
    "\n",
    "test_outputs = []\n",
    "test_trgs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        src = data[0][0].to(DEVICE)\n",
    "        max_len = data[1][0].to(DEVICE)\n",
    "        try:\n",
    "            anw = torch.nonzero(data[2][0]).to(DEVICE)[0]\n",
    "        except:\n",
    "            continue\n",
    "        trg = data[3][0].to(DEVICE)\n",
    "        # print(src.shape, trg.shape)\n",
    "\n",
    "        for index in anw:\n",
    "            # LSTM\n",
    "            # output, _, _ = model(src) \n",
    "            \n",
    "            # GRU\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "            # transformer\n",
    "            # src_mask = model.generate_square_subsequent_mask(src.shape[1]).to(src.device)\n",
    "            # output, _ = model(src, src_mask)\n",
    "\n",
    "            # informer\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "\t\t\t# pyraformer\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "\t\t\t# n_beats\n",
    "            # output = model(src.view(src.size(0), -1))\n",
    "            \n",
    "\t\t\t# nlinear\n",
    "            # output = model(src) \n",
    "            # print(output.shape)\n",
    "\t\n",
    "            # test_outputs.append(output[index])\n",
    "            # test_trgs.append(trg[index])\n",
    "\n",
    "            # if attention added to above\n",
    "            output = model(src, index, max_len)\n",
    "\n",
    "            test_outputs.append(output)\n",
    "            test_trgs.append(trg[index])\n",
    "\n",
    "# save_path = f'../데이터/Checkpoint/transformer/attention/default/transformer_attention_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_{5}'\n",
    "# with open(f'{save_path}_test_rmses.txt', 'w') as f:\n",
    "#     for item in test_rmses:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "# with open(f'{save_path}_test_mses.txt', 'w') as f:\n",
    "#     for item in test_mses:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "# with open(f'{save_path}_test_maes.txt', 'w') as f:\n",
    "#     for item in test_maes:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "test_outputs = torch.FloatTensor(test_outputs)\n",
    "test_trgs = torch.FloatTensor(test_trgs)  \n",
    "\n",
    "test_rmse = rmse(test_outputs, test_trgs)\n",
    "test_mse = mse(test_outputs, test_trgs)\n",
    "test_mae = mae(test_outputs, test_trgs)\n",
    "\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "print(f'Test MSE: {test_mse:.4f}')\n",
    "print(f'Test MAE: {test_mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = torch.load('../데이터/Checkpoint/embedding/default/embedding_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_13.pth', map_location=DEVICE)\n",
    "dataset = Apartment_Complex_Dataset(embedding_model, table_1, table_2, table_3, embedding_dim, window_size, 'ML', DEVICE)\n",
    "dataset_length = len(dataset)\n",
    "train_size = int(train_ratio * dataset_length)\n",
    "# train_indices = range(0, train_size)\n",
    "val_size = int(val_ratio * dataset_length)\n",
    "# val_indices = range(train_size, train_size + val_size)\n",
    "test_size = int(test_ratio * dataset_length)\n",
    "test_indices = range(train_size + val_size, dataset_length)\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "# val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=False, drop_last=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=batch, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm\n",
    "model = joblib.load(f'../데이터/Checkpoint/lightgbm/lightgbm_batch_64_ws_12.pkl')\n",
    "\n",
    "# catboost\n",
    "# model = joblib.load(f'../데이터/Checkpoint/catboost/catboost_batch_64_ws_12.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "      mse = np.mean((y_true - y_pred) ** 2)\n",
    "      return np.sqrt(mse)\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "      return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mae(y_pred, y_true):\n",
    "      return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 20.7914\n",
      "Test MSE: 432.2820\n",
      "Test MAE: 20.7664\n"
     ]
    }
   ],
   "source": [
    "test_rmses = []\n",
    "test_mses = []\n",
    "test_maes = []\n",
    "\n",
    "test_outputs = []\n",
    "test_trgs = []\n",
    "\n",
    "for data in test_dataloader:\n",
    "    X, y = data[0].squeeze().cpu().numpy(), data[1].squeeze().cpu().numpy()\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    test_outputs.append(y_pred)\n",
    "    test_trgs.append(y)\n",
    "\n",
    "save_path = f'../데이터/Checkpoint/lightgbm/lightgbm_batch_{batch}_ws_{window_size}'\n",
    "with open(f'{save_path}_test_rmses.txt', 'w') as f:\n",
    "    for item in test_rmses:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open(f'{save_path}_test_mses.txt', 'w') as f:\n",
    "    for item in test_mses:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open(f'{save_path}_test_maes.txt', 'w') as f:\n",
    "    for item in test_maes:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "test_rmse = rmse(y_pred, y)\n",
    "test_mse = mse(y_pred, y)\n",
    "test_mae = mae(y_pred, y)\n",
    "\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "print(f'Test MSE: {test_mse:.4f}')\n",
    "print(f'Test MAE: {test_mae:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
